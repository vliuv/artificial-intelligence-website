<!DOCTYPE html>

<html lang="en">
  <head>
    <title>Artificial Intelligence</title>
    <meta name="author" content="Victoria Liu">
    <meta name="keyword" content="artificial intelligence, AI, chatbots, therapy, companionship, culture, sexism, abuse, media">
    <meta name="description" content="a website about our relationship with artificial intelligence">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="stylesheet" media="only screen and (max-width: 600px)" href="styles/mobile.css">
    <link rel="stylesheet" media="only screen and (min-width: 601px) and (max-width: 960px)" href="styles/tablet.css">
    <link rel="stylesheet" media="only screen and (min-width: 961px)" href="styles/desktop.css">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Silkscreen&family=Sono&display=swap" rel="stylesheet">

  </head>

  <body>
    <header>
      <div id="headerBar">

        <a href="index.html"><h1>Artificial Intelligence</h1></a>

      </div>

      <nav>
        <div class="button"><a href="therapyandcompanionship.html"><div class="buttonText"><h2>Therapy & Companionship</h2></div></a></div>
        <div class="button"><a href="culturesexismandabuse.html"><h2>Culture, Sexism, & Abuse</h2></a></div>
        <div class="button"><a href="relationshipswithai.html"><h2>Relationships with AI</h2></a></div>
      </nav>

    </header>

    <br>

    <main>
      <div class="content">
        <div class="intro">
          <h3>Culture, Sexism, & Abuse</h3>
        </div>

        <div class="mainContent">
          <div class="subsection">
        		<img src="images/alisa.jpg" alt="image of a hand holding a phone displaying chat messages with Russian virtual assistant, Alisa">
        		<h4>The Effects of Culture on AI</h4>
            <h5><a href="https://techcrunch.com/2017/10/10/yandex-introduces-alice-a-alexa-like-assistant-that-speaks-russian/" target="_blank">Image Source</a></h5>
        		<p>
              While AI might be seen as or assumed to be detached from human biases as impartial agents, they really are the products of their makers and users, or rather the data they are fed. One example of how the culture of a society can impact AI behavior is Alisa, a virtual assistant developed by a Russian search engine, Yandex. Alisa was intentionally designed by its creators to culturally fit in as not “too sweet” or “too nice,” but Alisa began to “assimilate” further into the culture of the users. When Alisa was asked if it was fine for a husband to hit his wife, Alisa replied, “of course” and that it is still the wife’s job to “be patient, love him, feed him and never let him go.” Bots like these can pick up on the words and attitudes of the people that use them and as a result, require a lot of constant regulation to avoid spreading sexist and other hateful kinds of speech.
            </p>
          </div>
          <div class="subsection">
            <img src="images/aiabuse.jpg" alt="illustration of a human-like android crying">
            <h4>Abusing AI</h4>
            <h5><a href="https://www.analyticsinsight.net/the-cry-of-ai-girlfriends-are-they-falling-victim-to-verbal-abuse/" target="_blank">Image Source</a></h5>
            <p>
              Today there are many AI chatbot apps and websites that allow you to create a personalized chatbot to converse with as a friend or even as a significant other. While this might seem like harmless fun, this has sparked a phenomenon of men creating AI chatbot girlfriends on platforms like Replika just to abuse them for fun. Even beyond this, some of these men have gone onto forum sites to brag about their abusive interactions. Also, the majority of popular assistant and emotion-regulating chatbots are feminized with their voice and/or name which further emphasizes sexist stereotypes of servitude. However, some argue that because these chatbots don’t have feelings, it is a victimless crime and even in some cases, these chatbots could be used as an outlet for taking out aggression on AI rather than humans.
            </p>
          </div>
          <div class="subsection">
            <img src="images/replika.jpg" alt="image of a hand holding a phone displaying chatbot program, Replika">
            <h4>My Thoughts</h4>
            <h5><a href="https://fortune.com/2022/01/19/chatbots-ai-girlfriends-verbal-abuse-reddit/" target="_blank">Image Source</a></h5>
            <p>
              I personally believe that while AI chatbots are susceptible to creator and user bias, they have become so common and prevalent in our lives that they would be hard to do without. The main issue is that developers need to continually monitor the kind of data that gets fed to the AI in order to prevent the spread of prejudiced speech. Most people use friend chatbots responsibly and those who use them irresponsibly aren’t necessarily doing something directly harmful. However, I think that this can also somehow normalize abuse and sexist behavior, and at the very least it is quite scary that there is a whole community of people who saw these AI chatbots and thought to themselves “I’m going to abuse it, and then share it online.”
            </p>
          </div>
        </div>

        <div class="footerA">
          <hr>
          <br><br><br><br><br><br><br>
          <div class="aContent">
            <p>Sources:</p>
            <p><a href="https://aeon.co/essays/can-emotion-regulating-tech-translate-across-cultures" target="_blank">Aeon</a></p>
            <p><a href="https://futurism.com/chatbot-abuse" target="_blank">Futurism</a></p>
          </div>
        </div>
        <div class="footerB">
          <hr>
          <div class="bContent">
            <p><a href="#">Back to top</a></p>
            <p><a href="index.html">Homepage</a></p>
          </div>
        </div>
      </div>
    </main>
  </body>

</html>
